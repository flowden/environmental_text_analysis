{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9a1810",
   "metadata": {},
   "source": [
    "### Word Frequecy in Discourses of Delay texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6f7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing all of my modules and data\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Path to my txt files\n",
    "data_folder = \"/Users/finn/Dropbox/Brown_2021-2022/SOC 2961M/Final Project/Discourses_of_Delay_Dictionary/Testimony_as_txts\"\n",
    "\n",
    "# Opening each txt file in folder\n",
    "delay_examples = []\n",
    "for file in os.listdir(data_folder):\n",
    "    with open(os.path.join(data_folder, file), 'r', encoding = \"ISO-8859-1\") as f:\n",
    "       text = f.read()\n",
    "       delay_examples.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f454af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating my Dictionaries\n",
    "\n",
    "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1MhB60vzde7KT9Ti6eQtimmWvYAEersI4zK3L_gwDNA8/edit#gid=0\"\n",
    "spreadsheet_url = spreadsheet_url.replace(\"/edit#gid=\", \"/export?format=csv&gid=\")\n",
    "\n",
    "df = pd.read_csv(spreadsheet_url, header=0)\n",
    "\n",
    "discourse_dict = {}\n",
    "for row in df.iterrows():\n",
    "    delay_method = row[1][\"Sub-category\"]\n",
    "    dict_words = row[1][\"Short_dict\"].split(\", \")\n",
    "    discourse_dict[delay_method] = dict_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2cc8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Processing my inported data into a dictionary\n",
    "\n",
    "# Cleaning each example in delay_examples\n",
    "delay_testimony = []\n",
    "\n",
    "for example in delay_examples:\n",
    "    # Spliting long string with all text into list of lowercase words\n",
    "    example = example.lower().split()\n",
    "\n",
    "    # Removing stopwords from example\n",
    "    someStopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    exampleCleaned = []\n",
    "    for word in example:\n",
    "        if word in someStopwords:\n",
    "            continue\n",
    "        else:\n",
    "            exampleCleaned.append(word)\n",
    "\n",
    "    # Removing punctuation\n",
    "    exampleNoPunct = []\n",
    "    for word in exampleCleaned:\n",
    "        for mark in set(string.punctuation):\n",
    "            word=word.replace(mark, '')\n",
    "        exampleNoPunct.append(word)\n",
    "    \n",
    "    # Appending cleaned data as list to delay_examples\n",
    "    delay_testimony.append(exampleNoPunct)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6894db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Individualism:\n",
      "{'Total Matches': 404, 'Total Words': 113590, 'Proportion Words Matched': 0.003556651113654371}\n",
      "\n",
      "2. The 'free rider' excuse:\n",
      "{'Total Matches': 231, 'Total Words': 113590, 'Proportion Words Matched': 0.0020336297209261377}\n",
      "\n",
      "3. Whataboutism:\n",
      "{'Total Matches': 113, 'Total Words': 113590, 'Proportion Words Matched': 0.000994805880799366}\n",
      "\n",
      "4. All talk, little action:\n",
      "{'Total Matches': 276, 'Total Words': 113590, 'Proportion Words Matched': 0.002429791354872788}\n",
      "\n",
      "5. Fossil fuel solutionism:\n",
      "{'Total Matches': 88, 'Total Words': 113590, 'Proportion Words Matched': 0.0007747160841623383}\n",
      "\n",
      "6. No sticks, just carrots:\n",
      "{'Total Matches': 84, 'Total Words': 113590, 'Proportion Words Matched': 0.0007395017167004138}\n",
      "\n",
      "7. Technological optimism:\n",
      "{'Total Matches': 292, 'Total Words': 113590, 'Proportion Words Matched': 0.002570648824720486}\n",
      "\n",
      "8. Appeal to well-being:\n",
      "{'Total Matches': 489, 'Total Words': 113590, 'Proportion Words Matched': 0.004304956422220266}\n",
      "\n",
      "9. Policy perfectionism:\n",
      "{'Total Matches': 17, 'Total Words': 113590, 'Proportion Words Matched': 0.000149661061713179}\n",
      "\n",
      "10. Appeal to social justice:\n",
      "{'Total Matches': 92, 'Total Words': 113590, 'Proportion Words Matched': 0.0008099304516242627}\n",
      "\n",
      "11. Change is impossible:\n",
      "{'Total Matches': 13, 'Total Words': 113590, 'Proportion Words Matched': 0.00011444669425125452}\n",
      "\n",
      "12. Doomism:\n",
      "{'Total Matches': 14, 'Total Words': 113590, 'Proportion Words Matched': 0.00012325028611673562}\n"
     ]
    }
   ],
   "source": [
    "### Implementing Dictionary Methods on my Corpus\n",
    "robustness_dict = {}\n",
    "robustness_dict[\"MA_CT_testimony\"] = delay_testimony\n",
    "\n",
    "# Helper function to help print results\n",
    "def print_results(results_dict: dict):\n",
    "    \"\"\"prints the results of apply_dict\"\"\"\n",
    "    total_matches = 0\n",
    "    total_words = 0\n",
    "    propotion_matched = 0\n",
    "    num_testimony = len(delay_testimony)\n",
    "    for testimony in results_dict:\n",
    "        total_matches += results_dict[testimony][\"Matches\"]\n",
    "        total_words += results_dict[testimony][\"Total Words\"]\n",
    "    propotion_matched = total_matches/total_words\n",
    "    \n",
    "    # Creating output\n",
    "    total_results = {}\n",
    "    total_results[\"Total Matches\"] = total_matches\n",
    "    total_results[\"Total Words\"] = total_words\n",
    "    total_results[\"Proportion Words Matched\"] = propotion_matched\n",
    "    \n",
    "    print(total_results) \n",
    "\n",
    "# For each group's combined texts, I create a dictionary to store the data I get from each comparison\n",
    "def apply_dict(robustness_data: dict, DOD_dict: list) -> dict:\n",
    "    \"\"\"applies given dictionary to data created in cell above\"\"\"\n",
    "    results_dict = {}\n",
    "    count = 0\n",
    "    for data_type in robustness_data:\n",
    "        for example in robustness_data[data_type]:\n",
    "            # Creating results-storing dict, word count, and match count variables\n",
    "            temp_results = {}\n",
    "            totalWords = 0\n",
    "            matches = 0\n",
    "            count += 1\n",
    "\n",
    "            # Looping through every word in my text, counting:\n",
    "            # 1) the total words and 2) those words that match the words in our dictionary\n",
    "            for word in example:\n",
    "                totalWords +=1\n",
    "                if word in DOD_dict:\n",
    "                    matches += 1\n",
    "            proportionWords = matches/totalWords\n",
    "            # Adding results to a dictionary for each group's text\n",
    "            temp_results[\"Matches\"] = matches\n",
    "            temp_results[\"Total Words\"] = totalWords\n",
    "            temp_results[\"Proportion Words Matched\"] = proportionWords\n",
    "            # Adding each type of robustness_data to temp_results\n",
    "            results_dict[\"testimony \" + str(count)] = temp_results\n",
    "        \n",
    "    # Calling helper function to help print results\n",
    "    print_results(results_dict)\n",
    "\n",
    "# Printing my results\n",
    "count = 1\n",
    "for delay in discourse_dict:\n",
    "    print(\"\\n\" + str(count)+ \". \" + delay + \":\")\n",
    "    apply_dict(robustness_dict, discourse_dict[delay])\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61e52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
