{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9a1810",
   "metadata": {},
   "source": [
    "### Word Frequecy in Discourses of Delay texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6f7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing all of my modules and data\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Path to my txt files\n",
    "data_folder = \"/Users/finnianlowden/Documents/GitHub/environmental_text_analysis/MA_CT_opposition_testimony/Testimony_as_txts\"\n",
    "\n",
    "# Opening each txt file in folder\n",
    "testimony = {\"MA\": {}, \"CT\": {}}\n",
    "all_texts = []\n",
    "\n",
    "for file in os.listdir(data_folder):\n",
    "    file_name_as_list = file.split(\"_\")\n",
    "    state = file_name_as_list[0]\n",
    "    try:\n",
    "        year = int(file_name_as_list[1])\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    year = int(file_name_as_list[1])\n",
    "    \n",
    "    with open(os.path.join(data_folder, file), 'r', encoding = \"ISO-8859-1\") as f:\n",
    "        text = f.read()\n",
    "        if year not in testimony[state]:\n",
    "            testimony[state][year] = [text]\n",
    "        else:\n",
    "            testimony[state][year].append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f454af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing my Dictionaries\n",
    "\n",
    "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1MhB60vzde7KT9Ti6eQtimmWvYAEersI4zK3L_gwDNA8/edit#gid=0\"\n",
    "spreadsheet_url = spreadsheet_url.replace(\"/edit#gid=\", \"/export?format=csv&gid=\")\n",
    "\n",
    "df = pd.read_csv(spreadsheet_url, header=0)\n",
    "\n",
    "discourse_dict = {}\n",
    "for row in df.iterrows():\n",
    "    delay_method = row[1][\"Sub-category\"]\n",
    "    dict_words = row[1][\"Current_dict\"].split(\", \")\n",
    "    discourse_dict[delay_method] = dict_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2cc8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Processing my imported data into a dictionary\n",
    "\n",
    "# Cleaning each example in delay_examples\n",
    "cleaned_testimony = {\"MA\": {}, \"CT\": {}}\n",
    "num_testimony = 0\n",
    "for state in testimony:\n",
    "    for year in testimony[state]:\n",
    "        for item in testimony[state][year]:\n",
    "            num_testimony += 1\n",
    "            \n",
    "            # Removing line breaks\n",
    "            item = item.replace(\" \\n\", \"\")\n",
    "            \n",
    "            # Spliting long string with all text into list of lowercase words\n",
    "            item = item.lower().split()\n",
    "\n",
    "            # Removing stopwords from example\n",
    "            someStopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "            itemCleaned = []\n",
    "            for word in item:\n",
    "                if word in {\"your\", \"our\", \"you\", \"we\", \"one's\", \"too\", \"not\"}: # Saving these words for bigrams\n",
    "                    itemCleaned.append(word)\n",
    "                elif word in someStopwords:\n",
    "                    continue\n",
    "                else:\n",
    "                    itemCleaned.append(word)\n",
    "\n",
    "            # Removing punctuation\n",
    "            itemNoPunct = []\n",
    "            for word in itemCleaned:\n",
    "                for mark in set(string.punctuation):\n",
    "                    word = word.replace(mark, '')\n",
    "                itemNoPunct.append(word)\n",
    "\n",
    "            # Appending cleaned data as list to delay_examples\n",
    "            if year not in cleaned_testimony[state]:\n",
    "                cleaned_testimony[state][year] = [itemNoPunct]\n",
    "            else:\n",
    "                cleaned_testimony[state][year].append(itemNoPunct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6894db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementing Dictionary Methods on my Corpus\n",
    "\n",
    "# Helper function to calculate results\n",
    "def calculate_results(results_dict: dict):\n",
    "    \"\"\"prints the results of apply_dict\"\"\"\n",
    "    total_results = {}\n",
    "    \n",
    "    # Adding all years in range to total_results\n",
    "    for year in range(1980, 2021):\n",
    "            total_results[year] = {\"total_matches\": \"\", \"total_words\": \"\", \"Proportion Words Matched\": \"\"}\n",
    "    \n",
    "    # Adding matches and total words to total_results\n",
    "    for testimony in results_dict:\n",
    "        year = int(testimony.split(\"_\")[1])\n",
    "        if total_results[year][\"total_matches\"] == \"\":\n",
    "            total_results[year][\"total_matches\"] = results_dict[testimony][\"Matches\"]\n",
    "        if total_results[year][\"total_words\"] == \"\":\n",
    "            total_results[year][\"total_words\"] = results_dict[testimony][\"Total Words\"]\n",
    "        total_results[year][\"total_matches\"] += results_dict[testimony][\"Matches\"]\n",
    "        total_results[year][\"total_words\"] += results_dict[testimony][\"Total Words\"]\n",
    "    \n",
    "    # Calculating prop_match\n",
    "    for year in total_results:\n",
    "        if type(total_results[year][\"total_words\"]) is not str:\n",
    "            if total_results[year][\"total_words\"] == 0:\n",
    "                prop_match = \"\"\n",
    "            else:\n",
    "                prop_match = total_results[year][\"total_matches\"] / total_results[year][\"total_words\"]\n",
    "            total_results[year][\"Proportion Words Matched\"] = prop_match\n",
    "    return total_results\n",
    "\n",
    "# For each group's combined texts, I create a dictionary to store the data I get from each comparison\n",
    "def apply_dict(testimony_dict: dict, DOD_dict: set) -> dict:\n",
    "    \"\"\"applies given dictionary to data cleaned in cell above\"\"\"\n",
    "    results_dict = {}\n",
    "    count = 0\n",
    "    for state in testimony_dict:\n",
    "        for year in testimony_dict[state]:\n",
    "            for item in testimony_dict[state][year]:\n",
    "                # Creating results-storing dict, word count, and match count variables\n",
    "                temp_results = {}\n",
    "                totalWords = 0\n",
    "                matches = 0\n",
    "                count += 1\n",
    "\n",
    "                # Looping through every word in my text, counting:\n",
    "                # 1) the total words and 2) those words that match the words in our dictionary   \n",
    "                last_word = \"\"\n",
    "                for word in item:\n",
    "                    if len(word) <= 1: # Filtering out short words\n",
    "                        continue\n",
    "                    else:\n",
    "                        totalWords +=1\n",
    "                        # Unigrams\n",
    "                        if word in DOD_dict: \n",
    "                            matches += 1\n",
    "                        # Bigrams\n",
    "                        bigram_space = last_word + \" \" + word\n",
    "                        bigram_no_space = last_word + \" \" + word\n",
    "                        if bigram_space in DOD_dict or bigram_no_space in DOD_dict: \n",
    "                            matches += 1\n",
    "                        last_word = word\n",
    "                    proportionWords = matches/totalWords\n",
    "                # Adding results to a dictionary for each group's text\n",
    "                temp_results[\"Matches\"] = matches\n",
    "                temp_results[\"Total Words\"] = totalWords\n",
    "                temp_results[\"Proportion Words Matched\"] = proportionWords\n",
    "                # Adding each type of robustness_data to temp_results\n",
    "                results_dict[state + \"_\" + str(year) + \"_\" + str(count)] = temp_results\n",
    "    return calculate_results(results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe61e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling results\n",
    "results = {} # All data\n",
    "csv_results = {} # Data needed for csv\n",
    "\n",
    "# Adding all years to csv_results\n",
    "temp_results = {}\n",
    "for year in range(1980, 2021):\n",
    "    temp_results[year] = \"\"\n",
    "\n",
    "for delay in discourse_dict:\n",
    "    results[delay] = apply_dict(cleaned_testimony, set(discourse_dict[delay]))\n",
    "    csv_results[delay] = temp_results.copy()\n",
    "    sum_data = 0\n",
    "    count = 0\n",
    "    for year in csv_results[delay]:\n",
    "        # Change from average matches to prop_match\n",
    "        # Average values\n",
    "#         data = results[delay][year][\"Proportion Words Matched\"]\n",
    "#         if type(data) is not str:\n",
    "#             count += 1\n",
    "#             sum_data += data\n",
    "#     for year in csv_results[delay]:\n",
    "#         data = results[delay][year][\"Proportion Words Matched\"]\n",
    "#         if type(data) is not str:\n",
    "#             csv_results[delay][int(year)] = sum_data / count\n",
    "        # Average values\n",
    "        # Aggregate values\n",
    "        prop_match = results[delay][year][\"total_matches\"] # total_matches, total_words, or Proportion Words Matched\n",
    "        csv_results[delay][int(year)] = prop_match\n",
    "\n",
    "# Creating list of dictionaries for DictWriter\n",
    "output_list = []\n",
    "for delay in csv_results:\n",
    "    csv_results[delay][\"Year\"] = delay\n",
    "    output_list.append(csv_results[delay])\n",
    "\n",
    "keys = csv_results[delay].keys()\n",
    "\n",
    "# Change from prop_match to average matches\n",
    "# with open(\"testimony_data_prop_match.csv\", \"w\") as my_file:\n",
    "with open(\"testimony_data_matches.csv\", \"w\") as my_file:\n",
    "    dict_writer = csv.DictWriter(my_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbcd16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
