{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9a1810",
   "metadata": {},
   "source": [
    "### Word Frequecy in Discourses of Delay texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6f7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing all of my modules and data\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Path to my txt files\n",
    "data_folder = \"/Users/finnianlowden/Documents/GitHub/environmental_text_analysis/MA_CT_opposition_testimony/Testimony_as_txts\"\n",
    "\n",
    "# Opening each txt file in folder\n",
    "delay_examples = []\n",
    "for file in os.listdir(data_folder):\n",
    "    with open(os.path.join(data_folder, file), 'r', encoding = \"ISO-8859-1\") as f:\n",
    "       text = f.read()\n",
    "       delay_examples.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f454af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating my Dictionaries\n",
    "\n",
    "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1MhB60vzde7KT9Ti6eQtimmWvYAEersI4zK3L_gwDNA8/edit#gid=0\"\n",
    "spreadsheet_url = spreadsheet_url.replace(\"/edit#gid=\", \"/export?format=csv&gid=\")\n",
    "\n",
    "df = pd.read_csv(spreadsheet_url, header=0)\n",
    "\n",
    "discourse_dict = {}\n",
    "for row in df.iterrows():\n",
    "    delay_method = row[1][\"Sub-category\"]\n",
    "    dict_words = row[1][\"Current_dict\"].split(\", \")\n",
    "    discourse_dict[delay_method] = dict_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2cc8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Processing my imported data into a dictionary\n",
    "\n",
    "# Cleaning each example in delay_examples\n",
    "delay_testimony = []\n",
    "\n",
    "for example in delay_examples:\n",
    "    # Spliting long string with all text into list of lowercase words\n",
    "    example = example.lower().split()\n",
    "\n",
    "    # Removing stopwords from example\n",
    "    someStopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    exampleCleaned = []\n",
    "    for word in example:\n",
    "        if word in someStopwords:\n",
    "            continue\n",
    "        else:\n",
    "            exampleCleaned.append(word)\n",
    "\n",
    "    # Removing punctuation\n",
    "    exampleNoPunct = []\n",
    "    for word in exampleCleaned:\n",
    "        for mark in set(string.punctuation):\n",
    "            word=word.replace(mark, '')\n",
    "        exampleNoPunct.append(word)\n",
    "    \n",
    "    # Appending cleaned data as list to delay_examples\n",
    "    delay_testimony.append(exampleNoPunct)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6894db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementing Dictionary Methods on my Corpus\n",
    "robustness_dict = {}\n",
    "robustness_dict[\"MA_CT_testimony\"] = delay_testimony\n",
    "\n",
    "# Helper function to help print results\n",
    "def calculate_results(results_dict: dict):\n",
    "    \"\"\"prints the results of apply_dict\"\"\"\n",
    "    total_matches = 0\n",
    "    total_words = 0\n",
    "    propotion_matched = 0\n",
    "    num_testimony = len(delay_testimony)\n",
    "    for testimony in results_dict:\n",
    "        total_matches += results_dict[testimony][\"Matches\"]\n",
    "        total_words += results_dict[testimony][\"Total Words\"]\n",
    "    propotion_matched = total_matches/total_words\n",
    "    \n",
    "    # Creating output\n",
    "    total_results = {}\n",
    "    total_results[\"Total Matches\"] = total_matches\n",
    "    total_results[\"Total Words\"] = total_words\n",
    "    total_results[\"Proportion Words Matched\"] = propotion_matched\n",
    "    \n",
    "    return total_results\n",
    "\n",
    "# For each group's combined texts, I create a dictionary to store the data I get from each comparison\n",
    "def apply_dict(robustness_data: dict, DOD_dict: list) -> dict:\n",
    "    \"\"\"applies given dictionary to data created in cell above\"\"\"\n",
    "    results_dict = {}\n",
    "    count = 0\n",
    "    for data_type in robustness_data:\n",
    "        for example in robustness_data[data_type]:\n",
    "            # Creating results-storing dict, word count, and match count variables\n",
    "            temp_results = {}\n",
    "            totalWords = 0\n",
    "            matches = 0\n",
    "            count += 1\n",
    "\n",
    "            # Looping through every word in my text, counting:\n",
    "            # 1) the total words and 2) those words that match the words in our dictionary\n",
    "            for word in example:\n",
    "                totalWords +=1\n",
    "                if word in DOD_dict:\n",
    "                    matches += 1\n",
    "            proportionWords = matches/totalWords\n",
    "            # Adding results to a dictionary for each group's text\n",
    "            temp_results[\"Matches\"] = matches\n",
    "            temp_results[\"Total Words\"] = totalWords\n",
    "            temp_results[\"Proportion Words Matched\"] = proportionWords\n",
    "            # Adding each type of robustness_data to temp_results\n",
    "            results_dict[\"testimony \" + str(count)] = temp_results\n",
    "        \n",
    "    # Calling helper function to help print results\n",
    "    return calculate_results(results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe61e52b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zg/x813n1xn7r1f_k68nnt2v9t80000gn/T/ipykernel_20501/1013353583.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdict_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdict_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdict_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/csv.py\u001b[0m in \u001b[0;36mwriterows\u001b[0;34m(self, rowdicts)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_to_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m# Guard Sniffer's type checking against builds that exclude complex()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/csv.py\u001b[0m in \u001b[0;36m_dict_to_list\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dict_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrasaction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mwrong_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrong_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 raise ValueError(\"dict contains fields not in fieldnames: \"\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# Compiling results\n",
    "results = {}\n",
    "for delay in discourse_dict:\n",
    "    results[delay] = apply_dict(robustness_dict, discourse_dict[delay])[\"Proportion Words Matched\"]\n",
    "\n",
    "keys = results.keys()\n",
    "\n",
    "with open(\"testimony_data.csv\", \"w\") as my_file:\n",
    "    dict_writer = csv.DictWriter(my_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1917e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
